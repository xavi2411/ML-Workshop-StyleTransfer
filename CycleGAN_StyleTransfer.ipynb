{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer using CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses generative adversarial networks (GANs) to perform neural style transfer. In particular, the method being used is called CycleGAN, which is a method for perfoming image-to-image translation based on GANs as described in <a href=\"https://arxiv.org/abs/1703.10593\" class=\"external\">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a> (Zhu et al.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial does not give the implementation for the CycleGAN model. The code for the model is available in the official [CycleGAN repository](https://github.com/junyanz/CycleGAN). Then, here we are giving the necessary steps to run the CycleGAN model (train and test) and a pretrained model for style transfer will also be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the repository mentioned above, this notebook will use an updated repository including CycleGAN and Pix2Pix models that can be found [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
